---
title: "Data Aggregation"
output: html_notebook
---

Data aggregation script for Hemauer, Saunders, and Desmarais.

Last updated: 5/21/25

TODO: Run the original models from the original papers--don't use network models for now.
  -Use PR Curve (for imbalanced data)

```{r}

### Preprocessing

library(tidyverse)
library(haven)
library(car)
library(eha)
library(sandwich)
library(lmtest)
library(rsample)
library(randomForest)
library(caret)
library(MLeval)
library(pROC)
library(PRROC)
library(xgboost)

set.seed(1337)

boehmke_2017_full <- read_dta("boehmke_analysis/replication_data/boehmke2017.dta")
boushey_2016_full <- read_dta("boushey_analysis/replication_data/boushey2016.dta")
bricker_lacombe_2021_full <- read_dta("bricker_lacombe_analysis/replication_data/monadic_analysis_largen.dta")
karch_2016_full <- read_dta("karch_analysis/replication_data/karch2016.dta")

```

ORIGINAL REPLICATIONS


Boehmke replication estimates are exact.

```{r}

### Boehmke et al. 2017 
## PEHA

# Covariates
covariates <- c("srcs_decay","nbrs_lag","rpcpinc","totpop","legp_squire",
                "citi6010","unif_rep","unif_dem","time","time_sq","time_cube")

# Remove Data After Adoption and Omit Missing
boehmke_2017 <- na.omit(boehmke_2017_full[, c("state", "year", "statepol", "adopt", covariates)])

# Character to Factor
boehmke_2017$state <- as.factor(boehmke_2017$state)

# Fit
boehmke_formula <- as.formula(paste("adopt ~ state +", paste(c(covariates), collapse = "+")))

peha_boehmke <- glm(boehmke_formula, data = boehmke_2017, family = binomial)

coeftest(peha_boehmke, vcov = vcovHC, cluster = ~ statepol)

```


Boushey replication estimates are close, but not identical to the original estimates. 

```{r}

### Boushey 2016 
## PEHA

# Covariates
covariates <- c("policycongruent","gub_election","elect2", "hvd_4yr", "fedcrime",
                "leg_dem_per_2pty","dem_governor","insession","propneighpol",
                "citidist","squire_prof86","citi6008","crimespendpc","crimespendpcsq",
                "violentthousand","pctwhite","stateincpercap","logpop","counter","counter2","counter3")

# Remove data after adoption and omit missing
boushey_2016 <- na.omit(boushey_2016_full)

# Fit
boushey_formula <- as.formula(paste("dvadopt ~", paste(c(covariates), collapse = "+")))

peha_boushey <- glm(boushey_formula, data = boushey_2016, family = binomial)

coeftest(peha_boushey, cluster = ~ styear)

```


Bricker and Lacombe replication estimates are close, but not identical to the original estimates. 

# Maybe missing robust std. errors?
# My data has more obs. then reported in the article model

```{r}

### Bricker & Lacombe 2021
## PEHA

# Covariates
covariates <- c("std_score","initiative","init_sigs","std_population",
                "std_citideology","unified","std_income","std_legp_squire",
                "duration","durationsq","durationcb", "year")

# Character to Factor
bricker_lacombe_2021_full$year <- as.factor(bricker_lacombe_2021_full$year)

# Remove data after adoption and omit missing
bricker_2021 <- na.omit(bricker_lacombe_2021_full)

# Fit
bricker_formula <- as.formula(paste("adoption ~", paste(c(covariates), collapse = "+")))

peha_bricker <- glm(bricker_formula, data = bricker_2021, family = binomial)

coeftest(peha_bricker, vcov = vcovHC, cluster = ~ stateyear)

```


Karch replicaton estimates are nowhere close to the original estimates.

```{r}

### Karch 2016
## PEHA

# Remove data after adoption and omit missing
karch_2016 <- na.omit(karch_2016_full)

# Fit
peha_karch <- glm(adopt ~ traditional + nborsstd + traditional*nborsstd+prevadoptstd + traditional*prevadoptstd + 
                  complexity + traditional*complexity + igrole + traditional*igrole + regov + traditional*regov + 
                  unified + traditional*unified + perdemstd + traditional*perdemstd + incpcadjstd + traditional*incpcadjstd + 
                  exppcadjstd + traditional*exppcadjstd + logpopstd + traditional*logpopstd + collegstd + traditional*collegstd + 
                  perurbanstd + traditional*perurbanstd + profstd + traditional*profstd,  
                  data = karch_2016) 

coeftest(peha_karch, vcov = vcovHC, cluster = ~ stateyear)

```

RANDOM FORESTS

Notes for Below:
  # Could bootstrap rare strata
  # What covariates to holdout from training?
    # Do we want to train on state or year?
      # Holding out state, year, and policy type makes prediction essentially random (51% balanced accuracy)
      # I think this could be an interesting point to build on. State-level covariates may be useless for prediction
  # Not sure if train/test is stratified by state, year, policy. Caret trainControl() may do this automatically
  # Could use elastic net for feature selection; will not work on RF itself because it is non-linear
  # Could adjust RF weights and/or thresholds

```{r}

### Boehmke 2017 
## RF

# Covariates
covariates <- c("srcs_decay","nbrs_lag","rpcpinc","totpop","legp_squire",
                "citi6010","unif_rep","unif_dem","time","time_sq","time_cube")

# Remove Data After Adoption and Omit Missing
boehmke_2017 <- na.omit(boehmke_2017_full[, c("state", "year", "policy", "statepol", "adopt", covariates)])

# Split
train_index <- createDataPartition(boehmke_2017$adopt, p = 0.8, list = FALSE)
boehmke_train_data <- boehmke_2017[train_index, ]
boehmke_test_data <- boehmke_2017[-train_index, ]

# Convert to factor with specified levels
boehmke_train_data$adopt <- ifelse(boehmke_train_data$adopt == 1, "yes", "no")
boehmke_train_data$adopt <- factor(boehmke_train_data$adopt, levels = c("no", "yes"))

# Setup CV
train_control <- trainControl(method = "cv", number = 3,
                              sampling = "smote",
                              classProbs = TRUE, # Cannot use TRUE with 0 and 1 class labels because RF converts to character
                              savePredictions = "all",
                              summaryFunction = twoClassSummary)

# Define grid search
tune_grid <- expand.grid(.mtry = c(2, 3, 4, 5))

# Train
boehmke_rf <- train(adopt ~ ., data = boehmke_train_data, method = "rf", 
                    trControl = train_control, metric = "ROC") # tuneGrid = tune_grid

# Test
predictions <- predict(boehmke_rf, newdata = boehmke_test_data[, -c(5)])

# Output
boehmke_test_data$adopt <- ifelse(boehmke_test_data$adopt == 1, "yes", "no")
boehmke_test_data$adopt <- factor(boehmke_test_data$adopt, levels = c("no", "yes"))
confusionMatrix(predictions, boehmke_test_data$adopt, positive = "yes")

# PR Curve
boehmke_pr <- evalm(boehmke_rf)

```

CODE SNIPPETS

```{r}

# Elastic Net for Linear Models
tune_grid <- expand.grid(alpha = seq(0, 1, by = 0.1),             # Alpha from 0 (Ridge) to 1 (Lasso)
                         lambda = seq(0.001, 0.1, by = 0.005))    # Penalty parameter

```

