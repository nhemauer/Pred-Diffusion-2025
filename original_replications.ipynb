{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b971567",
   "metadata": {},
   "source": [
    "Original Replication Script for Hemauer, Saunders, and Desmarais\n",
    "\n",
    "Note: This file does not include any gridsearch or hyperparameter tuning. This is just a basic inference replication script.\n",
    "\n",
    "Last updated: 06/10/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e45f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3465d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.181244\n",
      "         Iterations 8\n",
      "Logistic Regression took 0.09 seconds\n",
      "                Coef.  Std.Err.          z         P>|z|    [0.025    0.975]\n",
      "const       -4.932003  0.379749 -12.987549  1.439637e-38 -5.676296 -4.187709\n",
      "srcs_decay   8.526663  0.438523  19.444071  3.271493e-84  7.667175  9.386151\n",
      "nbrs_lag     0.392840  0.022265  17.643892  1.133760e-69  0.349202  0.436479\n",
      "rpcpinc      0.573760  0.074898   7.660526  1.851727e-14  0.426962  0.720558\n",
      "totpop       0.090543  0.028298   3.199597  1.376197e-03  0.035080  0.146007\n",
      "legp_squire -1.088974  0.687671  -1.583569  1.132918e-01 -2.436784  0.258836\n",
      "citi6010     0.009835  0.003520   2.793907  5.207549e-03  0.002936  0.016734\n",
      "unif_rep    -0.020446  0.076089  -0.268708  7.881541e-01 -0.169578  0.128687\n",
      "unif_dem     0.062910  0.066440   0.946871  3.437047e-01 -0.067310  0.193131\n",
      "time        -0.135390  0.017594  -7.695380  1.410739e-14 -0.169872 -0.100907\n",
      "time_sq      0.007239  0.001445   5.009828  5.447877e-07  0.004407  0.010072\n",
      "time_cube   -0.000128  0.000031  -4.132885  3.582384e-05 -0.000188 -0.000067\n"
     ]
    }
   ],
   "source": [
    "### Boehmke et al. 2017 Replication\n",
    "# Coef estimates are exact, constant estimate is not.\n",
    "\n",
    "# Data\n",
    "boehmke_2017_full = pd.read_stata(r\"data/boehmke2017.dta\")\n",
    "\n",
    "covariates = [\"srcs_decay\",\"nbrs_lag\",\"rpcpinc\",\"totpop\",\"legp_squire\",\n",
    "                \"citi6010\",\"unif_rep\",\"unif_dem\",\"time\",\"time_sq\",\"time_cube\"]\n",
    "boehmke_2017 = boehmke_2017_full[[\"state\", \"year\", \"statepol\", \"adopt\"] + covariates].dropna()\n",
    "\n",
    "# Define X and y\n",
    "X = boehmke_2017.drop(columns = ['adopt', 'year', 'statepol']).copy()\n",
    "X = pd.get_dummies(X, columns = ['state'], drop_first = True)  # drop_first avoids perfect multicollinearity\n",
    "X = sm.add_constant(X)\n",
    "y = boehmke_2017['adopt']\n",
    "\n",
    "# Fit Logistic Regression model\n",
    "start_time = time.time()\n",
    "logistic = sm.Logit(y.astype(float), X.astype(float)).fit(cov_type = \"cluster\", cov_kwds = {'groups': boehmke_2017['statepol']})\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Logistic Regression took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Extract summary table\n",
    "summary_df = logistic.summary2().tables[1]\n",
    "\n",
    "# Filter out state dummy variables\n",
    "summary_filtered = summary_df[~summary_df.index.str.startswith(\"state_\")]\n",
    "\n",
    "print(summary_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ded6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.222943\n",
      "         Iterations 8\n",
      "Logistic Regression took 0.02 seconds\n",
      "                     Coef.  Std.Err.          z          P>|z|    [0.025  \\\n",
      "const            -6.264146  1.150959  -5.442547   5.252402e-08 -8.519984   \n",
      "policycongruent   0.363093  0.057571   6.306875   2.847255e-10  0.250256   \n",
      "gub_election     -0.022066  0.090321  -0.244305   8.069945e-01 -0.199092   \n",
      "elect2            0.032447  0.076580   0.423706   6.717805e-01 -0.117647   \n",
      "hvd_4yr           0.002792  0.004137   0.674931   4.997198e-01 -0.005316   \n",
      "fedcrime          1.223034  0.396732   3.082770   2.050833e-03  0.445454   \n",
      "leg_dem_per_2pty  0.005372  0.002913   1.844528   6.510622e-02 -0.000336   \n",
      "dem_governor      0.052652  0.068702   0.766377   4.434519e-01 -0.082002   \n",
      "insession         1.687741  0.227934   7.404505   1.316410e-13  1.240998   \n",
      "propneighpol      2.359892  0.098142  24.045647  9.270677e-128  2.167537   \n",
      "citidist         -0.041644  0.003499 -11.903366   1.136683e-32 -0.048501   \n",
      "squire_prof86    -0.240328  0.344954  -0.696695   4.859936e-01 -0.916425   \n",
      "citi6008         -0.005838  0.003661  -1.594469   1.108311e-01 -0.013013   \n",
      "crimespendpc     -0.000342  0.002487  -0.137352   8.907522e-01 -0.005216   \n",
      "crimespendpcsq    0.000003  0.000005   0.622723   5.334664e-01 -0.000007   \n",
      "violentthousand  -0.000978  0.020061  -0.048774   9.610994e-01 -0.040298   \n",
      "pctwhite          0.002186  0.006022   0.363038   7.165762e-01 -0.009617   \n",
      "stateincpercap    0.022370  0.009349   2.392919   1.671492e-02  0.004047   \n",
      "logpop            0.061880  0.057589   1.074507   2.825956e-01 -0.050993   \n",
      "counter           0.009061  0.021681   0.417935   6.759950e-01 -0.033432   \n",
      "counter2         -0.002528  0.001253  -2.016598   4.373744e-02 -0.004984   \n",
      "counter3          0.000043  0.000020   2.173511   2.974189e-02  0.000004   \n",
      "\n",
      "                    0.975]  \n",
      "const            -4.008309  \n",
      "policycongruent   0.475930  \n",
      "gub_election      0.154960  \n",
      "elect2            0.182542  \n",
      "hvd_4yr           0.010899  \n",
      "fedcrime          2.000615  \n",
      "leg_dem_per_2pty  0.011081  \n",
      "dem_governor      0.187306  \n",
      "insession         2.134484  \n",
      "propneighpol      2.552247  \n",
      "citidist         -0.034787  \n",
      "squire_prof86     0.435770  \n",
      "citi6008          0.001338  \n",
      "crimespendpc      0.004533  \n",
      "crimespendpcsq    0.000013  \n",
      "violentthousand   0.038341  \n",
      "pctwhite          0.013989  \n",
      "stateincpercap    0.040693  \n",
      "logpop            0.174754  \n",
      "counter           0.051555  \n",
      "counter2         -0.000071  \n",
      "counter3          0.000082  \n"
     ]
    }
   ],
   "source": [
    "### Boushey 2016 Replication (Table 2: Model 2)\n",
    "# Coef and constant estimates are exact.\n",
    "\n",
    "# Data\n",
    "boushey_2016_full = pd.read_stata(r\"data/boushey2016.dta\")\n",
    "\n",
    "# Covariates\n",
    "covariates = [\"policycongruent\",\"gub_election\",\"elect2\", \"hvd_4yr\", \"fedcrime\",\n",
    "                \"leg_dem_per_2pty\",\"dem_governor\",\"insession\",\"propneighpol\",\n",
    "                \"citidist\",\"squire_prof86\",\"citi6008\",\"crimespendpc\",\"crimespendpcsq\",\n",
    "                \"violentthousand\",\"pctwhite\",\"stateincpercap\",\"logpop\",\"counter\",\"counter2\",\"counter3\"]\n",
    "boushey_2016 = boushey_2016_full[[\"state\", \"styear\", \"dvadopt\"] + covariates].dropna()\n",
    "\n",
    "# Define X and y\n",
    "X = boushey_2016[covariates].copy()\n",
    "X = sm.add_constant(X)\n",
    "y = boushey_2016['dvadopt']\n",
    "\n",
    "# Fit Logistic Regression model\n",
    "start_time = time.time()\n",
    "logistic = sm.Logit(y.astype(float), X.astype(float)).fit(cov_type = \"cluster\", cov_kwds = {'groups': boushey_2016['styear']})\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Logistic Regression took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Extract summary table\n",
    "summary_df = logistic.summary2().tables[1]\n",
    "\n",
    "# Filter out state dummy variables\n",
    "summary_filtered = summary_df[~summary_df.index.str.startswith(\"state_\")]\n",
    "\n",
    "print(summary_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c432d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "len(ident) should match the number of columns of exog_vc",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m exog_re = np.ones((\u001b[38;5;28mlen\u001b[39m(data), \u001b[32m1\u001b[39m))  \u001b[38;5;66;03m# random intercept\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Fit BinomialBayesMixedGLM (logit mixed model)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m model = \u001b[43msm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBinomialBayesMixedGLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madoption\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog_re\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m result = model.fit_vb()  \u001b[38;5;66;03m# Variational Bayes fit\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.summary())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\statsmodels\\genmod\\bayes_mixed_glm.py:1021\u001b[39m, in \u001b[36mBinomialBayesMixedGLM.__init__\u001b[39m\u001b[34m(self, endog, exog, exog_vc, ident, vcp_p, fe_p, fep_names, vcp_names, vc_names)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1011\u001b[39m              endog,\n\u001b[32m   1012\u001b[39m              exog,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1018\u001b[39m              vcp_names=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1019\u001b[39m              vc_names=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexog_vc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog_vc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mident\u001b[49m\u001b[43m=\u001b[49m\u001b[43mident\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvcp_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvcp_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfe_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfe_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfamilies\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfep_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfep_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvcp_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvcp_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvc_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvc_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(np.unique(endog) == np.r_[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]):\n\u001b[32m   1034\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mendog values must be 0 and 1, and not all identical\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\statsmodels\\genmod\\bayes_mixed_glm.py:231\u001b[39m, in \u001b[36m_BayesMixedGLM.__init__\u001b[39m\u001b[34m(self, endog, exog, exog_vc, ident, family, vcp_p, fe_p, fep_names, vcp_names, vc_names, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ident) != exog_vc.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m    230\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mlen(ident) should match the number of columns of exog_vc\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.issubdtype(ident.dtype, np.integer):\n\u001b[32m    234\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mident must have an integer dtype\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: len(ident) should match the number of columns of exog_vc"
     ]
    }
   ],
   "source": [
    "### Bricker & Lacombe 2021 (Table 3: Model 3)(Monadic Model)\n",
    "\n",
    "# This works in Stata, mixed effects logit doesn't really exist in Python...\n",
    "\n",
    " #melogit adoption std_score initiative init_sigs ///\n",
    " #std_pop std_citideology unified std_income std_legp_squire ///\n",
    " #duration  durationsq durationcb i.year || policyno:\n",
    " #estimates store m1\n",
    "\n",
    "# Data\n",
    "bricker_lacombe_2021_full = pd.read_stata(r\"data/bricker_lacombe2021.dta\")\n",
    "\n",
    "# Covariates\n",
    "covariates = [\"std_score\",\"initiative\",\"init_sigs\",\"std_population\",\n",
    "                \"std_citideology\",\"unified\",\"std_income\",\"std_legp_squire\",\n",
    "                \"duration\",\"durationsq\",\"durationcb\"]\n",
    "bricker_lacombe_2021 = bricker_lacombe_2021_full[[\"state\", \"year\", \"policy\", \"adoption\"] + covariates].dropna()\n",
    "\n",
    "# Define X and y\n",
    "X = pd.get_dummies(bricker_lacombe_2021, columns = ['year'], drop_first = True)  # drop_first avoids perfect multicollinearity\n",
    "y = bricker_lacombe_2021['adoption']\n",
    "\n",
    "# Replace periods with underscores in all column names\n",
    "X.columns = X.columns.str.replace('.', '_', regex = False)\n",
    "\n",
    "# Combine X and y into a single DataFrame\n",
    "data = X.copy()\n",
    "data['adoption'] = y\n",
    "\n",
    "# Make sure your outcome is binary\n",
    "data['adoption'] = data['adoption'].astype(int)\n",
    "\n",
    "# Fixed effects: all covariates + year dummies\n",
    "year_cols = [col for col in X.columns if col.startswith('year_')]\n",
    "exog = sm.add_constant(data[covariates + year_cols])  # add intercept\n",
    "\n",
    "# Random effects: random intercept for each policy (policyno)\n",
    "groups = data['policy'].astype('category').cat.codes  # convert to integer codes\n",
    "exog_re = np.ones((len(data), 1))  # random intercept\n",
    "\n",
    "# Fit BinomialBayesMixedGLM (logit mixed model)\n",
    "model = sm.BinomialBayesMixedGLM(data['adoption'], exog, exog_re, groups)\n",
    "result = model.fit_vb()  # Variational Bayes fit\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf520ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adoption ~ std_score + initiative + init_sigs + std_population + std_citideology + unified + std_income + std_legp_squire + duration + durationsq + durationcb + year_1991_0 + year_1992_0 + year_1993_0 + year_1994_0 + year_1995_0 + year_1996_0 + year_1997_0 + year_1998_0 + year_1999_0 + year_2000_0 + year_2001_0 + year_2002_0 + year_2003_0 + year_2004_0 + year_2005_0 + year_2006_0 + year_2007_0 + year_2008_0 + year_2009_0 + year_2010_0 + year_2011_0 + year_2012_0 + year_2013_0\n"
     ]
    }
   ],
   "source": [
    "print(formula)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
